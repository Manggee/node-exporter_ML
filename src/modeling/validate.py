import argparse
import json
import sys
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, Any

import joblib
import numpy as np
import pandas as pd
from xgboost import XGBRegressor
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import plotly.graph_objects as go
import plotly.io as pio
from sklearn.metrics import mean_absolute_error
import psycopg2
import psycopg2.extras  # ëŒ€ëŸ‰ ì‚½ì…

from src.features.feature_engineering import make_features
from src.modeling.train_tune import FeatureConfig

"""
- df_part1ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì„ df_part2 ë°ì´í„°ë¡œ ê²€ì¦í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""
# ---------------------------
# DB ì„¤ì • ë¡œë” (ì™¸ë¶€ íŒŒì¼)
# ---------------------------
def load_db_config(path: str) -> Dict[str, Any]:
    """
    db_config.jsonì—ì„œ ì ‘ì† ì •ë³´ë¥¼ ì½ì–´ psycopg2.connectì— ë§ê²Œ ë°˜í™˜.
    - 'database' í‚¤ë¥¼ 'dbname'ìœ¼ë¡œ ë§¤í•‘í•´ í˜¸í™˜ì„± í™•ë³´
    - ë¹ˆ ê°’/Noneì€ ì œê±°
    """
    if not os.path.exists(path):
        print(f"âŒ DB ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}", file=sys.stderr)
        sys.exit(90)

    with open(path, "r", encoding="utf-8") as f:
        cfg = json.load(f)

    # database -> dbname ë³´ì • (psycopg2 í‘œì¤€ í‚¤)
    if "database" in cfg and "dbname" not in cfg:
        cfg["dbname"] = cfg.pop("database")

    # ë¹ˆ ë¬¸ìì—´/None ì œê±°
    cfg = {k: v for k, v in cfg.items() if v not in ("", None)}
    return cfg


def build_dataset_for_validation(processed_csv_path: str, feat_cfg: Dict[str, Any]) -> tuple[pd.DataFrame, pd.Series]:
    """df_part2 ì „ì²´ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ í”¼ì²˜ì™€ íƒ€ê²Ÿì„ ìƒì„±"""
    try:
        df_proc = pd.read_csv(processed_csv_path, index_col='timestamp', parse_dates=['timestamp'])
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {processed_csv_path}", file=sys.stderr)
        sys.exit(1)

    if df_proc.empty:
        print("âŒ ë¡œë“œëœ ì „ì²˜ë¦¬ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.", file=sys.stderr)
        sys.exit(2)

    df_feat = make_features(
        df_proc,
        lags=feat_cfg.lags,
        rolling_window=feat_cfg.rolling_window,
        use_all_stats=feat_cfg.use_all_stats,
        use_holidays=feat_cfg.use_holidays,
        use_fourier=feat_cfg.use_fourier
    )

    target_base = "mean" if "mean" in df_feat.columns else "value"
    target_col = f"target_t+{feat_cfg.horizon}"
    df_feat[target_col] = df_feat[target_base].shift(-feat_cfg.horizon)
    df_feat = df_feat.dropna()

    y = df_feat[target_col].copy()
    X = df_feat.drop(columns=[target_col]).copy()

    return X, y


def save_validation_results_to_db(
    mae: float, y_val: pd.Series, y_pred: np.ndarray, horizon: int, db_config: Dict[str, Any]
):
    """ê²€ì¦ ê²°ê³¼ë¥¼ PostgreSQLì— ì €ì¥ (ë³µí•© PK + UPSERT, ì™¸ë¶€ íŒŒì¼ ì„¤ì • ì‚¬ìš©)"""
    conn = None
    try:
        conn = psycopg2.connect(**db_config)
        cur = conn.cursor()

        # í…Œì´ë¸” ìƒì„±: ë³µí•© PK (timestamp, horizon)
        cur.execute("""
            CREATE TABLE IF NOT EXISTS validation_results (
                timestamp       TIMESTAMP NOT NULL,
                horizon         INTEGER   NOT NULL,
                actual_value    REAL,
                predicted_value REAL,
                mae             REAL,
                created_at      TIMESTAMP,
                PRIMARY KEY (timestamp, horizon)
            );
        """)

        now = pd.Timestamp.now()
        records = [
            (
                (y_val.index[i].to_pydatetime()
                 if hasattr(y_val.index[i], "to_pydatetime")
                 else y_val.index[i]),
                int(horizon),
                float(y_val.iloc[i]),
                float(y_pred[i]),
                float(mae),
                now.to_pydatetime(),
            )
            for i in range(len(y_val))
        ]

        sql = """
            INSERT INTO validation_results
              (timestamp, horizon, actual_value, predicted_value, mae, created_at)
            VALUES %s
            ON CONFLICT (timestamp, horizon) DO UPDATE SET
              actual_value    = EXCLUDED.actual_value,
              predicted_value = EXCLUDED.predicted_value,
              mae             = EXCLUDED.mae,
              created_at      = EXCLUDED.created_at;
        """
        psycopg2.extras.execute_values(cur, sql, records, page_size=10000)
        conn.commit()
        print(f"âœ… ê²€ì¦ ê²°ê³¼ {len(records)}ê°œ UPSERT ì™„ë£Œ")

    except psycopg2.Error as e:
        if conn:
            conn.rollback()
        print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: {e}")
        raise
    finally:
        if conn:
            conn.close()


def main():
    BASE_DIR = Path(__file__).resolve().parent.parent

    parser = argparse.ArgumentParser()
    parser.add_argument("--config",  default=str(BASE_DIR / "models" / "best_model_config.json"), help="í•™ìŠµ ì‹œ ì €ì¥ëœ êµ¬ì„±(JSON)")
    parser.add_argument("--model", default=str(BASE_DIR / "models" / "best_model_xgb_model.joblib"), help="í•™ìŠµ ëª¨ë¸ ê²½ë¡œ")
    parser.add_argument("--scaler", default=str(BASE_DIR / "models" / "best_model_scaler.joblib"), help="ìŠ¤ì¼€ì¼ëŸ¬ ê²½ë¡œ")
    parser.add_argument("--out_prefix", default="best_model", help="íŒŒì¼ ì ‘ë‘ì‚¬ (ì˜ˆ: model_part1)")
    parser.add_argument("--db-config", default=str(BASE_DIR / "config" / "db_config.json"), help="DB ì ‘ì† ì •ë³´ JSON ê²½ë¡œ(ê¹ƒì— ì˜¬ë¦¬ì§€ ì•Šê¸°)")
    args = parser.parse_args()

    # í”¼ì²˜ ì´ë¦„ ëª©ë¡, ìµœì  í•˜ì´í¼, horizon ë“± ë©”íƒ€ ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” json íŒŒì¼ ë¡œë“œ
    with open(args.config, "r") as f:
        meta = json.load(f)

    if "trial" in meta and "feat_cfg" in meta["trial"]:
        feat_cfg = meta["trial"]["feat_cfg"]
        # ë”•ì…”ë„ˆë¦¬ë¥¼ FeatureConfig ê°ì²´ë¡œ ë³€í™˜ ğŸ‘‡
        feat_cfg = FeatureConfig(**feat_cfg)
    else:
        print("âŒ FeatureConfig ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. config íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.", file=sys.stderr)
        sys.exit(1)

    horizon = feat_cfg.horizon

    BASE_DIR = Path(__file__).resolve().parent.parent

    # íŒŒì¼ ê²½ë¡œë“¤ - ëª…í™•í•œ í´ë” êµ¬ì¡° ë°˜ì˜
    PROCESSED_PATH = BASE_DIR / "data" / f"{args.out_prefix}_preprocessed_part2.csv"
    MODEL_PATH = BASE_DIR / "models" / f"{args.out_prefix}_xgb_model.joblib"
    SCALER_PATH = BASE_DIR / "models" / f"{args.out_prefix}_scaler.joblib"

    model: XGBRegressor = joblib.load(MODEL_PATH)
    scaler = joblib.load(SCALER_PATH)

    # ê²€ì¦ìš© X, y ìƒì„±
    X_val, y_val = build_dataset_for_validation(PROCESSED_PATH, feat_cfg)

    # ìŠ¤ì¼€ì¼ transform (í›ˆë ¨ ê¸°ì¤€)
    X_val = X_val.copy()
    float_cols = getattr(scaler, "feature_names_in_", None)
    if float_cols is not None:
        cols_to_scale = [c for c in float_cols if c in X_val.columns]
        if cols_to_scale:
            X_val.loc[:, cols_to_scale] = scaler.transform(X_val[cols_to_scale])

    # ì˜ˆì¸¡ & MAE ê³„ì‚°
    y_pred_np = model.predict(X_val)
    y_pred = np.array([float(x) for x in y_pred_np])
    mae = mean_absolute_error(y_val, y_pred)

    print("\nâœ… df_part2 ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ì™„ë£Œ")
    print(f"  - ì˜ˆì¸¡ ì‹œì : t+{horizon} ({int(horizon) * 5}ë¶„ í›„)")
    print(f"  - ê²€ì¦ MAE: {mae:.4f}")

    # DB ì„¤ì • íŒŒì¼ ë¡œë“œ â†’ ì €ì¥
    db_config = load_db_config(args.db_config)
    save_validation_results_to_db(mae, y_val, y_pred, int(horizon), db_config)

    # ===== ì‹œê°í™” ì½”ë“œ ì‹œì‘ =====
    font_path = None
    if os.name == 'posix':
        try:
            if 'Darwin' in os.uname():
                font_path = '/System/Library/Fonts/AppleGothic.ttf'
            elif os.path.exists('/usr/share/fonts/truetype/nanum/NanumGothic.ttf'):
                font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
        except:
            pass
    elif os.name == 'nt':
        font_path = 'C:/Windows/Fonts/malgunbd.ttf'

    if font_path and os.path.exists(font_path):
        font_name = fm.FontProperties(fname=font_path).get_name()
        plt.rc('font', family=font_name)
    else:
        for font in fm.fontManager.ttflist:
            if 'Gothic' in font.name or 'Malgun' in font.name or 'Nanum' in font.name:
                plt.rc('font', family=font.name)
                break
    plt.rcParams['axes.unicode_minus'] = False
    # ===== 1. plot ì‹œê°í™” =====
    print("\nğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”...")

    plt.figure(figsize=(15, 7))
    plt.plot(y_val.index, y_val, label='ì‹¤ì œ ê°’ (df_part2)', color='blue', alpha=0.7)
    plt.plot(y_val.index, y_pred, label='ì˜ˆì¸¡ ê°’', color='red', linestyle='--')

    plt.title(f"df_part2 ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ (t+{horizon} = {int(horizon) * 5}ë¶„ í›„)")
    plt.xlabel("ì‹œì ")
    plt.ylabel("Node Load1")
    plt.legend()
    plt.grid(True)

    plt.xticks(rotation=45)
    plt.tight_layout()

    # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥í•˜ê¸°
    save_dir = Path.home() / "Code" / "ntels_Project" / "result"
    save_dir.mkdir(parents=True, exist_ok=True)
    ts_str = datetime.now().strftime("%Y%m%d-%H%M%S")
    outfile = save_dir / f"{ts_str}_ë² ì´ì§€ì•ˆìµœì í™”.png"

    fig = plt.gcf() # í˜„ì¬ figure ê°ì²´
    fig.savefig(outfile, dpi=150, bbox_inches="tight")
    print(f"plot ì €ì¥ ì™„ë£Œ : {outfile}")

    plt.show()
    # ===== plotly ì‹œê°í™” ì½”ë“œ ë =====


if __name__ == "__main__":
    main()