import argparse
import json
import random
import sys
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Tuple
import itertools

import numpy as np
import pandas as pd
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler
from xgboost import XGBRegressor
import joblib
import optuna  # Optuna ë¼ì´ë¸ŒëŸ¬ë¦¬ import

from src.data.load_data import load_and_prepare, DATA_PATH
from src.data.preprocess import preprocess_load_metric
from src.features.feature_engineering import make_features


# -----------------------------
# Config / Utilities
# -----------------------------
@dataclass
class FeatureConfig:
    lags: List[int]
    rolling_window: List[int]
    use_all_stats: bool
    horizon: int
    use_holidays: bool
    use_fourier: bool


@dataclass
class ModelConfig:
    n_estimators: int
    max_depth: int
    learning_rate: float
    subsample: float
    colsample_bytree: float
    reg_alpha: float
    reg_lambda: float
    min_child_weight: float


@dataclass
class TrialResult:
    feat_cfg: FeatureConfig
    model_cfg: ModelConfig
    mae: float
    n_train: int
    n_valid: int


def set_seed(seed: int = 42):
    random.seed(seed)
    np.random.seed(seed)


def time_split(
        X: pd.DataFrame, y: pd.Series, valid_ratio: float = 0.2
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
    assert 0 < valid_ratio < 1
    split_idx = int(len(X) * (1 - valid_ratio))
    X_tr, X_va = X.iloc[:split_idx].copy(), X.iloc[split_idx:].copy()
    y_tr, y_va = y.iloc[:split_idx].copy(), y.iloc[split_idx:].copy()
    return X_tr, X_va, y_tr, y_va


def build_dataset(df_processed: pd.DataFrame, feat_cfg: FeatureConfig) -> Tuple[pd.DataFrame, pd.Series]:
    df_feat = make_features(
        df_processed,
        lags=feat_cfg.lags,
        rolling_window=feat_cfg.rolling_window,
        use_all_stats=feat_cfg.use_all_stats,
        use_holidays=feat_cfg.use_holidays,
        use_fourier=feat_cfg.use_fourier,
    )
    target_base = "mean" if "mean" in df_feat.columns else "value"
    target_col = f"target_t+{feat_cfg.horizon}"
    df_feat[target_col] = df_feat[target_base].shift(-feat_cfg.horizon)
    df_feat = df_feat.dropna()

    y = df_feat[target_col].copy()
    X = df_feat.drop(columns=[target_col]).copy()
    return X, y


def train_evaluate(
        X: pd.DataFrame, y: pd.Series, model_cfg: ModelConfig, valid_ratio: float = 0.2
) -> Tuple[float, Dict[str, Any]]:
    X_tr, X_va, y_tr, y_va = time_split(X, y, valid_ratio=valid_ratio)

    float_cols = X_tr.select_dtypes(include=["float32", "float64"]).columns
    scaler = StandardScaler()

    X_tr = X_tr.copy();
    X_va = X_va.copy()
    X_tr.loc[:, float_cols] = scaler.fit_transform(X_tr[float_cols])
    X_va.loc[:, float_cols] = scaler.transform(X_va[float_cols])

    model = XGBRegressor(
        n_estimators=model_cfg.n_estimators,
        max_depth=model_cfg.max_depth,
        learning_rate=model_cfg.learning_rate,
        subsample=model_cfg.subsample,
        colsample_bytree=model_cfg.colsample_bytree,
        reg_alpha=model_cfg.reg_alpha,
        reg_lambda=model_cfg.reg_lambda,
        min_child_weight=model_cfg.min_child_weight,
        random_state=42,
        n_jobs=-1,
        tree_method="hist",
    )

    model.fit(X_tr, y_tr, verbose=False)

    pred = model.predict(X_va)
    mae = mean_absolute_error(y_va, pred)
    info = {
        "n_train": len(X_tr),
        "n_valid": len(X_va),
        "scaler": scaler,
        "num_cols": list(float_cols),
        "feature_names": list(X_tr.columns),
        "valid_ratio": valid_ratio,
    }
    return mae, info


# ë² ì´ì§€ì•ˆ ìµœì í™”ë¥¼ ìœ„í•œ objective í•¨ìˆ˜ ğŸ‘‡
def objective(trial, df_processed, valid_ratio: float = 0.2):  # <<< 1. ì—¬ê¸°ì— valid_ratio ì¶”ê°€
    # í”¼ì²˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³µê°„ ì •ì˜
    lags = trial.suggest_categorical('lags', ((1, 2, 3), (1, 2, 3, 4, 5)))
    rolling_window = trial.suggest_categorical('rolling_window', ((3, 6), (3, 6, 12)))
    use_all_stats = trial.suggest_categorical('use_all_stats', (True, False))
    use_holidays = trial.suggest_categorical('use_holidays', (True, False))
    use_fourier = trial.suggest_categorical('use_fourier', (True, False))
    horizon = trial.suggest_categorical('horizon', (1, 3))

    # ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³µê°„ ì •ì˜
    n_estimators = trial.suggest_int('n_estimators', 200, 700)
    max_depth = trial.suggest_int('max_depth', 4, 10)
    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.2, log=True)
    subsample = trial.suggest_float('subsample', 0.7, 1.0)
    colsample_bytree = trial.suggest_float('colsample_bytree', 0.7, 1.0)
    reg_alpha = trial.suggest_float('reg_alpha', 0.001, 10, log=True)
    reg_lambda = trial.suggest_float('reg_lambda', 0.001, 100, log=True)
    min_child_weight = trial.suggest_float('min_child_weight', 0.1, 100, log=True)

    feat_cfg = FeatureConfig(
        lags=lags,
        rolling_window=rolling_window,
        use_all_stats=use_all_stats,
        horizon=horizon,
        use_holidays=use_holidays,
        use_fourier=use_fourier
    )

    model_cfg = ModelConfig(
        n_estimators=n_estimators,
        max_depth=max_depth,
        learning_rate=learning_rate,
        subsample=subsample,
        colsample_bytree=colsample_bytree,
        reg_alpha=reg_alpha,
        reg_lambda=reg_lambda,
        min_child_weight=min_child_weight
    )

    try:
        X, y = build_dataset(df_processed, feat_cfg)
        if len(X) < 200:
            return float('inf')  # ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ ë¬´í•œëŒ€ ë°˜í™˜

        # <<< 2. train_evaluate í˜¸ì¶œ ì‹œ valid_ratio ì „ë‹¬
        mae, _ = train_evaluate(X, y, model_cfg, valid_ratio=valid_ratio)
        return mae
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ì–´ë–¤ ì—ëŸ¬ì¸ì§€ ì¶œë ¥í•˜ë©´ ë””ë²„ê¹…ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.
        print(f"An error occurred during trial: {e}")
        return float('inf')  # ì—ëŸ¬ ë°œìƒ ì‹œ ë¬´í•œëŒ€ ë°˜í™˜


def main():
    import os
    from pathlib import Path

    BASE_DIR = Path(__file__).resolve().parent.parent
    DATA_PATH = BASE_DIR / "data" / "node_metrics.csv"

    # ëª¨ë¸ ì €ì¥ ê²½ë¡œ ì„¤ì • ğŸ‘‡
    MODELS_DIR = BASE_DIR / "models"
    MODELS_DIR.mkdir(parents=True, exist_ok=True)  # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±

    parser = argparse.ArgumentParser()
    parser.add_argument("--csv", default=DATA_PATH, help="ì›ë³¸ CSV ê²½ë¡œ")
    parser.add_argument("--valid_ratio", type=float, default=0.2, help="ê²€ì¦ ë¹„ìœ¨")
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--trials", type=int, default=100, help="ìµœì í™” ì‹œë„ íšŸìˆ˜")
    parser.add_argument("--out_prefix", default="best_model", help="ì‚°ì¶œë¬¼ íŒŒì¼ëª… ì ‘ë‘ì‚¬")
    args = parser.parse_args()

    set_seed(args.seed)

    # print("ğŸ“¥ ë¡œë“œ ì¤‘...")
    # df_raw = load_and_prepare(args.csv)
    # print("âœ… raw:", df_raw.shape)
    #
    # print("ğŸ”„ ì „ì²˜ë¦¬ ì¤‘...")
    # df_processed = preprocess_load_metric(df_raw)
    # print("âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„°:", df_processed.shape)
    #
    # mid_point = len(df_processed) // 2
    # df_part1 = df_processed.iloc[:mid_point].copy()
    # df_part2 = df_processed.iloc[mid_point:].copy()
    #
    # print(f"âœ… df_part1 í¬ê¸°: {len(df_part1)}")
    # print(f"âœ… df_part2 í¬ê¸°: {len(df_part2)}")
    #
    # # ì „ì²˜ë¦¬ ë°ì´í„° ì €ì¥ ê²½ë¡œ ë³€ê²½ ğŸ‘‡
    # df_part1_path = BASE_DIR / "data" / f"{args.out_prefix}_preprocessed_part1.csv"
    # df_part2_path = BASE_DIR / "data" / f"{args.out_prefix}_preprocessed_part2.csv"
    # df_part1.to_csv(df_part1_path)
    # df_part2.to_csv(df_part2_path)
    # print(f"âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {df_part1_path} ì™€ {df_part2_path}")
    #
    # df_processed = df_part1

    # ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ë°”ë¡œ ë¶ˆëŸ¬ì™€ì„œ ì‚¬ìš© ğŸ‘‡
    preprocessed_path = BASE_DIR / "data" / f"{args.out_prefix}_preprocessed_part1.csv"

    print(f"ğŸ“¥ ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ ì¤‘... ({preprocessed_path})")
    try:
        df_processed = pd.read_csv(preprocessed_path, index_col='timestamp', parse_dates=['timestamp'])
        print(f"âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df_processed.shape}")
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {preprocessed_path}", file=sys.stderr)
        sys.exit(1)

    study = optuna.create_study(direction='minimize')
    print(f"ğŸ” ë² ì´ì§€ì•ˆ ìµœì í™” ì‹œì‘. ì´ {args.trials}íšŒ íƒìƒ‰.")
    study.optimize(lambda trial: objective(trial, df_processed), n_trials=args.trials, show_progress_bar=True)

    # ëª¨ë“  íƒìƒ‰ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥ ğŸ‘‡
    print("\nâœ… ëª¨ë“  íƒìƒ‰ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥ ì¤‘...")
    try:
        df_trials = study.trials_dataframe()
        df_trials.to_csv(MODELS_DIR / f"{args.out_prefix}_trials.csv", index=False)
        print(f"âœ… ëª¨ë“  íƒìƒ‰ ê²°ê³¼ê°€ {MODELS_DIR / f'{args.out_prefix}_trials.csv'} íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ íƒìƒ‰ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    best_trial = study.best_trial

    print("\nğŸ ìµœì  êµ¬ì„±ìœ¼ë¡œ ì¬í•™ìŠµ & ì €ì¥ ì¤‘...")
    feat_cfg = FeatureConfig(**{k: v for k, v in best_trial.params.items() if k in FeatureConfig.__annotations__})
    model_cfg = ModelConfig(**{k: v for k, v in best_trial.params.items() if k in ModelConfig.__annotations__})

    X, y = build_dataset(df_processed, feat_cfg)
    X_tr, X_va, y_tr, y_va = time_split(X, y, valid_ratio=args.valid_ratio)

    float_cols = X_tr.select_dtypes(include=["float32", "float64"]).columns
    scaler = StandardScaler()

    X_tr.loc[:, float_cols] = scaler.fit_transform(X_tr[float_cols])
    X_va.loc[:, float_cols] = scaler.transform(X_va[float_cols])

    model = XGBRegressor(
        n_estimators=model_cfg.n_estimators,
        max_depth=model_cfg.max_depth,
        learning_rate=model_cfg.learning_rate,
        subsample=model_cfg.subsample,
        colsample_bytree=model_cfg.colsample_bytree,
        reg_alpha=model_cfg.reg_alpha,
        reg_lambda=model_cfg.reg_lambda,
        min_child_weight=model_cfg.min_child_weight,
        random_state=42,
        n_jobs=-1,
        tree_method="hist",
        verbosity=0
    )
    model.fit(X_tr, y_tr, verbose=False)

    pred = model.predict(X_va)
    mae = mean_absolute_error(y_va, pred)

    meta = {
        "trial": {
            'feat_cfg': asdict(feat_cfg),
            'model_cfg': asdict(model_cfg),
            'mae': float(mae)
        },
        "final_valid_mae": float(mae),
        "feature_names": list(X_tr.columns),
        "valid_ratio": args.valid_ratio,
        "csv_path": str(args.csv),
    }

    # ìµœì¢… ëª¨ë¸, ìŠ¤ì¼€ì¼ëŸ¬, config ì €ì¥ ê²½ë¡œ ë³€ê²½ ğŸ‘‡
    joblib.dump(model, MODELS_DIR / f"{args.out_prefix}_xgb_model.joblib")
    joblib.dump(scaler, MODELS_DIR / f"{args.out_prefix}_scaler.joblib")
    with open(MODELS_DIR / f"{args.out_prefix}_config.json", "w") as f:
        json.dump(meta, f, indent=2, ensure_ascii=False)

    print("\nâœ… ì €ì¥ ì™„ë£Œ")
    print(f"  - ëª¨ë¸: {MODELS_DIR / f'{args.out_prefix}_xgb_model.joblib'}")
    print(f"  - ìŠ¤ì¼€ì¼ëŸ¬: {MODELS_DIR / f'{args.out_prefix}_scaler.joblib'}")
    print(f"  - êµ¬ì„±/ê²°ê³¼: {MODELS_DIR / f'{args.out_prefix}_config.json'}")
    print(f"  - ìµœì¢… ê²€ì¦ MAE: {mae:.4f}")
    print(f"  - ìµœì  FeatureConfig: {asdict(feat_cfg)}")
    print(f"  - ìµœì  ModelConfig: {asdict(model_cfg)}")


if __name__ == "__main__":
    main()